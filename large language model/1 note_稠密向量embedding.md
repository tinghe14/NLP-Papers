# ChatGPT使用指南——相似匹配

### 何为embedding
- token化之后，需要考虑如何表示这些token
    - 把所有字作为字典，序号就代表自己。一行一个字，每个字作为一个Token，此时，0=我，1=们，……，以此类推。拿中文来说，这个词表可能只要几千行，即使包含各种特殊符号、生僻字，也就2万个多点，我们假设词表大小为N。如何用这些数字表示一段文本：最简单的就是直接把id串起来，这样也不是不行，但是这种表达方式是一维的，也就是说只能表示一个特征。不太现实。另一种表示方法：one-hot编码。对每一个字都有N（词表大小）个特征，除了该字的ID位置值为1，其余都为0。此时，对每一个Token（字），它的表示就变成了一个一维向量，比如「我」：[1,0,...0]，这个向量的长度就是词表的大小N，它被称为「我」这个字的One-Hot表示。对于一段文本：我们一般会将每个Token的表示结合起来，结合方式可以采用求和或平均。这样，对于任意长度的任意文本，我们都能将其表示为固定大小的向量，非常方便进行各种矩阵或张量（三维以上的数组）计算，这对深度学习至关重要。
    - 实际不会用简单的1/0代表因为每个字词在句子中的作用不一样，所以会给不同token赋予不同权重。最常见的方法是使用在句子中出现的频率，那些高频的（但不是「的」「更」这样的虚词）被认为是重要的。这种方法不错，在深度学习之前很长一段时间里都是这样的，不过它有两个很大的问题：数据维度太高：太高的维度会导致向量在空间中聚集在一个非常狭窄的角落，模型难以训练； 数据稀疏，向量之间缺乏语义上的交互（语义鸿沟）：比如「我爱吃苹果」和「我爱用苹果」，前者是水果，后者是手机，怎么判断出来的呢？根据上下文。但由于现在这种表示方式，导致上下文之间是孤立的，所以模型学不到这个知识点。还有类似「我喜欢你」和「你喜欢我」这样会得到同样的表示，但其实是不同的意思。
    - embedding的主要思想：就是一组稠密向量，把特征固定在某一个维度D，比如256、300、768等等，这个不重要，总之不再是词表那么大的数字。这就避免了维度过高的问题。
利用自然语言文本的上下文关系学习一个稠密表示。也就是说，每个Token的表示不再是预先算好的了，而是在过程中学习到的，元素也不再是很多个0，而是每个位置都有一个小数，这D个小数构成了一个Token表示。至于D个特征到底是什么，不知道，也不重要。我们只需要知道这D个小数就表示这个Token。这些小数怎么来的？简单，随机来的。在模型训练过程中，会根据不同的上下文不断地更新这个参数，最后模型训练完后得到的这个矩阵就是Token的表示。我们完全可以把它当成一个黑盒子，输入一个X，根据标签Y不断更新参数，最终就得到一组参数，这些参数的名字就叫「模型」。 这种表示方法在深度学习早期（2013-2015年左右）比较流行，不过由于这个矩阵训练好后就固定不变了，这在有些时候就不合适。比如「你好坏」这句话在不同的情况下可能完全是不同的意思。

### 相关API
- openai LMAS embedding API
- 语意相似度：在自然语言处理领域，我们一般使用cosine相似度作为语义相似度的度量，评估两个向量在语义空间上的分布情况。
- ![cosine相似度](https://github.com/tinghe14/NLP-Papers/blob/0cead1c6b00a6f190db8e07563aa3e1d1186f914/large%20language%20model/1%20cosine%E7%9B%B8%E4%BC%BC%E5%BA%A6.png)
