
# 分布式集群系列：AI集群+大模型+分布式训练系统
https://www.bilibili.com/video/BV1ge411L7mi/?spm_id_from=333.788&vd_source=8b4794944ae27d265c752edb598636de
1. AI集群服务器架构：参数服务器模式-同步与异步并行-环同步算法
2. AI集群软硬件通信：通信软硬件实现-通信实现方式
3. 分布式通信原语：通信原语
4. 框架分布式功能：并行处理硬件架构-AI框架中的分布式训练
5. 大模型算法：挑战-算法结构-sota大模型
6. 分布式并行：数据并行-张量并行-自动并行-多维混合并行

## 简介：
- 深度学习训练耗时=（训练数据规模*单步计算量）/计算速率
    - 其中计算速率是可变因素，前两者是与模型相关，相对固定
    - 计算速率=单设备计算速率* 设备数 *多设备并行效率（加速比）
      - 单设备计算速率=moore定律+算法优化
      - 单设备计算速率：混合精度，算子融合，梯度累加
      - 设备数：数量多了就称为集群，要解决服务器架构，通信拓扑优化
      - 加速比：数据并行，模型并行，流水并行

## AI集群架构ps（ps/parameter server/参数服务器）服务器架构
设备数：设备数越多不一定计算速率越高，要解决服务器架构，通信拓扑优化
- 分布式：同步并行：必须等全部工作节点完成了本次通信后才能继续下一轮本地计算
  - 优点：本地计算和通信同步严格顺序化，能够容易的保证并行的执行逻辑与串行相同
  - 缺点：本地计算更早的工作节点需要等待其他工作节点处理，造成了计算硬件的浪费
- 分布式：异步并行：当前在device1的batch迭代完之后，与其他服务器进行通信传输网络模型的参数
    - 优点：执行效率尬拍，除了单机通信时间以外没有任何通行与执行之间的阻塞等待
    - 缺点：如果device1执行的更快的话不会等同一个batch的Device2的结果做Backward Propgation,就会导致网络模型训练不收敛，训练时间变长，模型参数反复使用导致无法工业化
- 分布式：半同步并行：通过动态限制进度推进范围，有限定的宽松同步章的通信协调并行
  - 比如device2执行太慢了，就不等他了，直接被覆盖，用大多数workers(devices)能够接受的时间窗口进行更新

如何在物理层面/网络拓扑进行通信的同步
- 环同步ring synchronization

总结：
1. 大规模分布式训练中主要使用参数服务器架构模式（ps），参数服务器分布在多个gpu是ps模式的一种特殊形态
2. ps架构通过集合通信来实现环同步，从而同步分布在多个gpu中的参数，ring all reduce是环同步的经典同步方式

接下来看03
